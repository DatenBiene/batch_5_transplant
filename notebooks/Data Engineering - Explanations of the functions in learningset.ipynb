{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
       "<script>\n",
       "function repeat_indent_string(n){\n",
       "    var a = \"\" ;\n",
       "    for ( ; n > 0 ; --n)\n",
       "        a += \"    \";\n",
       "    return a;\n",
       "}\n",
       "// look up into all sections and builds an automated menu //\n",
       "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
       "    var anchors = document.getElementsByClassName(\"section\");\n",
       "    if (anchors.length == 0) {\n",
       "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
       "    }\n",
       "    var i,t;\n",
       "    var text_menu = begin;\n",
       "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
       "    var ind = \"\";\n",
       "    var memo_level = 1;\n",
       "    var href;\n",
       "    var tags = [];\n",
       "    var main_item = 0;\n",
       "    var format_open = 0;\n",
       "    for (i = 0; i <= llast; i++)\n",
       "        tags.push(\"h\" + i);\n",
       "\n",
       "    for (i = 0; i < anchors.length; i++) {\n",
       "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
       "\n",
       "        var child = null;\n",
       "        for(t = 0; t < tags.length; t++) {\n",
       "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
       "            if (r.length > 0) {\n",
       "child = r[0];\n",
       "break;\n",
       "            }\n",
       "        }\n",
       "        if (child == null) {\n",
       "            text_memo += \"null\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        if (anchors[i].hasAttribute(\"id\")) {\n",
       "            // when converted in RST\n",
       "            href = anchors[i].id;\n",
       "            text_memo += \"#1-\" + href;\n",
       "            // passer à child suivant (le chercher)\n",
       "        }\n",
       "        else if (child.hasAttribute(\"id\")) {\n",
       "            // in a notebook\n",
       "            href = child.id;\n",
       "            text_memo += \"#2-\" + href;\n",
       "        }\n",
       "        else {\n",
       "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        var title = child.textContent;\n",
       "        var level = parseInt(child.tagName.substring(1,2));\n",
       "\n",
       "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
       "\n",
       "        if ((level < lfirst) || (level > llast)) {\n",
       "            continue ;\n",
       "        }\n",
       "        if (title.endsWith('¶')) {\n",
       "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
       "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
       "        }\n",
       "        if (title.length == 0) {\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        while (level < memo_level) {\n",
       "            text_menu += end_format + \"</ul>\\n\";\n",
       "            format_open -= 1;\n",
       "            memo_level -= 1;\n",
       "        }\n",
       "        if (level == lfirst) {\n",
       "            main_item += 1;\n",
       "        }\n",
       "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
       "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
       "            continue;\n",
       "        }\n",
       "        while (level > memo_level) {\n",
       "            text_menu += \"<ul>\\n\";\n",
       "            memo_level += 1;\n",
       "        }\n",
       "        text_menu += repeat_indent_string(level-2);\n",
       "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
       "        format_open += 1;\n",
       "    }\n",
       "    while (1 < memo_level) {\n",
       "        text_menu += end_format + \"</ul>\\n\";\n",
       "        memo_level -= 1;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    text_menu += send;\n",
       "    //text_menu += \"\\n\" + text_memo;\n",
       "\n",
       "    while (format_open > 0) {\n",
       "        text_menu += end_format;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    return text_menu;\n",
       "};\n",
       "var update_menu = function() {\n",
       "    var sbegin = \"\";\n",
       "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
       "    var send = \"\";\n",
       "    var begin_format = '<li>';\n",
       "    var end_format = '</li>';\n",
       "    var keep_item = -1;\n",
       "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
       "       begin_format, end_format);\n",
       "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
       "    menu.innerHTML=text_menu;\n",
       "};\n",
       "window.setTimeout(update_menu,2000);\n",
       "            </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jyquickhelper import add_notebook_menu\n",
    "add_notebook_menu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does learningset work ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook aims to explain how to use the functions in transplant.data.learningset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also a good sandbox to try new function or debug the original file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transplant.data.dataset import Dataset\n",
    "dataset=Dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usfull functions you won't call directly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions are used in the different functions so there are really usefull here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to merge static and dynamic data (after having been flatten)\n",
    "def merge_dyn_sta(X_train_static, X_train_dynamic, X_test_static, X_test_dynamic):\n",
    "    return pd.merge(X_train_static, X_train_dynamic, on='id_patient'), pd.merge(X_test_static, X_test_dynamic, on='id_patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center and reduce the data\n",
    "def center_reduce_data(W_train, W_test):\n",
    "    mean_train = W_train.mean()\n",
    "    std_train = W_train.std()\n",
    "\n",
    "    return (W_train-mean_train)/std_train, (W_test-mean_train)/std_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some information about the length and the date of the operations\n",
    "def add_start_end_length_op_to_static(X_stat, X_dyn):\n",
    "            #X_dyn.index.names=['index',None] #Parfois ne semblait pas marcher à cause du format \"grouped_by\"\n",
    "            #X_stat.index.names=['index']\n",
    "            \n",
    "            grouped_time = X_dyn.groupby(['id_patient'])['time']\n",
    "            \n",
    "            time_start_df = grouped_time.first().to_frame()\n",
    "            time_start_df.columns = ['start_operation']\n",
    "            #time_start_df['id_patient'] = time_start_df.index\n",
    "\n",
    "            X_return = pd.merge(X_stat, time_start_df, on='id_patient',right_index=True)\n",
    "\n",
    "            time_ends_df = grouped_time.last().to_frame()\n",
    "            time_ends_df.columns = ['ends_operation']\n",
    "            #time_ends_df['id_patient'] = time_ends_df.index\n",
    "\n",
    "            X_return = pd.merge(X_return, time_ends_df, on='id_patient',right_index=True)\n",
    "\n",
    "            X_return['length_op'] = (X_return['ends_operation'] - X_return['start_operation']).apply(lambda x: x.seconds//60)\n",
    "            \n",
    "            X_return['start_operation_year']=X_return['start_operation'].apply(lambda x: x.year)\n",
    "            X_return['start_operation_month']=X_return['start_operation'].apply(lambda x: x.month)\n",
    "            X_return['start_operation_day']=X_return['start_operation'].apply(lambda x: x.dayofyear)\n",
    "            \n",
    "            \n",
    "            X_return['ends_operation_year']=X_return['ends_operation'].apply(lambda x: x.year)\n",
    "            X_return['ends_operation_month']=X_return['ends_operation'].apply(lambda x: x.month)\n",
    "            X_return['ends_operation_day']=X_return['ends_operation'].apply(lambda x: x.dayofyear)\n",
    " \n",
    "\n",
    "            return X_return.drop(['ends_operation','start_operation'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merges Static and Dynamic (where we get the full time series)\n",
    "def get_timeseries_in_array(X_stat, X_dyn, dyn_to_drop=['id_patient', 'time']):\n",
    "\n",
    "            X_return = X_stat\n",
    "\n",
    "            grouped = X_dyn.groupby(['id_patient'])\n",
    "\n",
    "            list_time_serie_col = X_dyn.drop(dyn_to_drop, axis=1).columns\n",
    "\n",
    "            for i in list_time_serie_col:\n",
    "                df_muette = grouped[i].apply(np.array).to_frame()\n",
    "                df_muette['id_patient'] = df_muette.index\n",
    "                df_muette.index.names=['index']\n",
    "                X_return = pd.merge(X_return, df_muette, on='id_patient')\n",
    "\n",
    "            return X_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_static_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_static_filled():\n",
    "        # Function that return the train and test set of the static data where :\n",
    "        # - We transformed the string into numbers\n",
    "        # - We drop the columns with just Nan\n",
    "        # - We replace the remaning Nan with the train column mean\n",
    "        # - We make sure we got the same columns for the train and the test set\n",
    "        from transplant.data.dataset import Dataset\n",
    "        train_static_0, test_static_0 = Dataset().get_static()\n",
    "\n",
    "        train_static_str_to_num = train_static_0.apply(\n",
    "            pd.to_numeric, errors='coerce').dropna(1, how=\"all\") #string in numbers and drop if full of Nan\n",
    "\n",
    "        mean_train_static = train_static_str_to_num.mean() #get mean of train to fill empty values in train and test\n",
    "\n",
    "        train_static_filled = train_static_str_to_num.fillna(mean_train_static) \n",
    "        \n",
    "        test_static_filled = test_static_0.apply(\n",
    "            pd.to_numeric, errors='coerce').dropna(1, how=\"all\").fillna(mean_train_static) #drop strings and fill Nan\n",
    "                                                                                            # in test by mean in train\n",
    "\n",
    "        \n",
    "        # Same columns\n",
    "        drop_test = []\n",
    "        drop_train = []\n",
    "        train_static_columns = train_static_filled.columns\n",
    "        test_static_columns = test_static_filled.columns\n",
    "\n",
    "        for i in train_static_filled.columns:\n",
    "            if not(i in test_static_columns):\n",
    "                drop_train += [i]\n",
    "\n",
    "        for i in test_static_columns:\n",
    "            if not(i in train_static_filled.columns):\n",
    "                drop_test += [i]\n",
    "\n",
    "        train_static_filled = train_static_filled.drop(drop_train, axis=1)\n",
    "        test_static_filled = test_static_filled.drop(drop_test, axis=1)\n",
    "\n",
    "        return train_static_filled, test_static_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What it does :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input : None\n",
    "\n",
    "Output : Static train and test set usable for ML\n",
    "\n",
    "\n",
    "Function that return the train and test set of the static data where :\n",
    "        - We transformed the string into numbers\n",
    "        - We drop the columns with just Nan\n",
    "        - We replace the remaning Nan with the train column mean\n",
    "        - We make sure we got the same columns for the train and the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transplant.data.learningset import Learningset\n",
    "learningset=Learningset()\n",
    "\n",
    "train_static , test_static = learningset.get_static_filled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_donor</th>\n",
       "      <th>Aspirations_donor</th>\n",
       "      <th>BMI_donor</th>\n",
       "      <th>Donneur_CPT</th>\n",
       "      <th>Insuffisance_renale</th>\n",
       "      <th>LAS</th>\n",
       "      <th>PAPS</th>\n",
       "      <th>PFO</th>\n",
       "      <th>PF_donor</th>\n",
       "      <th>Poids</th>\n",
       "      <th>...</th>\n",
       "      <th>preoperative_mechanical_ventilation</th>\n",
       "      <th>preoperative_pulmonary_hypertension</th>\n",
       "      <th>preoperative_vasopressor</th>\n",
       "      <th>retransplant</th>\n",
       "      <th>sexe</th>\n",
       "      <th>super_urgence</th>\n",
       "      <th>thoracic_surgery_history</th>\n",
       "      <th>time_on_waiting_liste</th>\n",
       "      <th>transplanted_twice_during_study_period</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25.502925</td>\n",
       "      <td>5430.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.4</td>\n",
       "      <td>94.677165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>25.502925</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>25.502925</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age_donor  Aspirations_donor  BMI_donor  Donneur_CPT  \\\n",
       "324         20                  3  25.502925       5430.0   \n",
       "323         56                  3  25.502925       6750.0   \n",
       "328         22                  3  25.502925       6750.0   \n",
       "\n",
       "     Insuffisance_renale   LAS       PAPS  PFO  PF_donor  Poids  ...  \\\n",
       "324                    0  34.4  94.677165  0.0     490.0   76.0  ...   \n",
       "323                    0  35.8  35.000000  0.0     513.0   50.0  ...   \n",
       "328                    0  33.2  32.000000  0.0     301.0   70.0  ...   \n",
       "\n",
       "     preoperative_mechanical_ventilation  preoperative_pulmonary_hypertension  \\\n",
       "324                                  0.0                                  0.0   \n",
       "323                                  0.0                                  0.0   \n",
       "328                                  0.0                                  0.0   \n",
       "\n",
       "     preoperative_vasopressor  retransplant  sexe  super_urgence  \\\n",
       "324                       0.0             0     1              0   \n",
       "323                       0.0             0     1              0   \n",
       "328                       0.0             0     1              0   \n",
       "\n",
       "     thoracic_surgery_history  time_on_waiting_liste  \\\n",
       "324                         1                     16   \n",
       "323                         1                     33   \n",
       "328                         1                      7   \n",
       "\n",
       "     transplanted_twice_during_study_period  target  \n",
       "324                                       0       1  \n",
       "323                                       0       1  \n",
       "328                                       0       0  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_static.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_data_merged_dynamic_flatten_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_merged_dynamic_flatten_full(target_format=\"cls\", centered_reduced=False, full_df=False):\n",
    "        \n",
    "        from transplant.data.learningset import Learningset\n",
    "        learningset = Learningset()\n",
    "\n",
    "        train_static_0, test_static_0 = learningset.get_static_filled() #On prend les statics utilisables pour ML\n",
    "        train_dynamic_0, test_dynamic_0 = dataset.get_dynamic() \n",
    "        \n",
    "        train_dynamic_0 = train_dynamic_0.fillna(0) # On remplace les Nan par des 0 dans dynamic\n",
    "        test_dynamic_0 = test_dynamic_0.fillna(0)\n",
    "\n",
    "        train_static_1 = add_start_end_length_op_to_static(train_static_0, train_dynamic_0) #On obtient entre autre la longueur de l'opération \n",
    "        test_static_1 = add_start_end_length_op_to_static(test_static_0, test_dynamic_0)\n",
    "        \n",
    "        \n",
    "        liste_func=[np.mean,np.std,np.amax,np.amin] #Les fonctions qu'on applique sur les séries temporelle\n",
    "        liste_func_name=['mean','std','max','min']\n",
    "        \n",
    "        train_glob_0, test_glob_0 = train_static_1 , test_static_1\n",
    "\n",
    "        for i in range(len(liste_func)) :\n",
    "            \n",
    "            func=liste_func[i]\n",
    "    \n",
    "            train_grouped=train_dynamic_0.drop(['time'],axis=1).groupby(['id_patient'], as_index=False) #On enregistre les groupes\n",
    "            test_grouped=test_dynamic_0.drop(['time'],axis=1).groupby(['id_patient'], as_index=False)\n",
    "    \n",
    "            train_id=train_grouped['id_patient'].apply(np.mean)  #On conserve le id du patient\n",
    "            test_id=test_grouped['id_patient'].apply(np.mean)\n",
    "    \n",
    "   \n",
    "            train_dynamic_flat = train_grouped.apply(func)   #On applique la fonction\n",
    "            test_dynamic_flat = test_grouped.apply(func)\n",
    "\n",
    "            train_dynamic_flat.rename(columns=lambda x: x+'_'+liste_func_name[i] if x!='id_patient' else x, inplace=True)\n",
    "            test_dynamic_flat.rename(columns=lambda x: x+'_'+liste_func_name[i]  if x!='id_patient' else x, inplace=True)\n",
    "    \n",
    "            train_dynamic_flat['id_patient']=train_id\n",
    "            test_dynamic_flat['id_patient']=test_id\n",
    "    \n",
    "            train_glob_0, test_glob_0 = merge_dyn_sta(train_glob_0, train_dynamic_flat, test_glob_0, test_dynamic_flat)\n",
    "    \n",
    "        if full_df :\n",
    "            return train_glob_0, test_glob_0\n",
    "\n",
    "        dic_to_One_Hot = {0: [1, 0], 1: [0, 1]}\n",
    "\n",
    "        y_train_cls = np.array(train_glob_0['target'])\n",
    "        y_train_hot = np.array(list(train_glob_0['target'].map(dic_to_One_Hot)))\n",
    "\n",
    "        y_test_cls = np.array(test_glob_0['target'])\n",
    "        y_test_hot = np.array(list(test_glob_0['target'].map(dic_to_One_Hot)))\n",
    "\n",
    "        if centered_reduced:\n",
    "            X_train, X_test = center_reduce_data(train_glob_0.drop(['target'], axis=1), test_glob_0.drop(['target'], axis=1))\n",
    "\n",
    "            X_train = np.array(X_train)\n",
    "            X_test = np.array(X_test)\n",
    "\n",
    "        else:\n",
    "            X_train = np.array(train_glob_0.drop(['target'], axis=1))\n",
    "            X_test = np.array(test_glob_0.drop(['target'], axis=1))\n",
    "\n",
    "        # Return\n",
    "        if target_format == \"cls\":\n",
    "            return X_train, X_test, y_train_cls, y_test_cls, train_glob_0.drop(['target'], axis=1).columns\n",
    "\n",
    "        if target_format == \"One_Hot\":\n",
    "            return X_train, X_test, y_train_hot, y_test_hot, train_glob_0.drop(['target'], axis=1).columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What it does :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input : \n",
    "\n",
    "    -target_format=\"cls\" if you want the target as 0 or 1 , \"One_Hot\" if you want the target to be [1,0] or [0,1]\n",
    "    \n",
    "    -centered_reduced=True if you want your data (except the target) to have mean 0 and var 1 (for train and we use the same transformation for the test set). False if you don't want\n",
    "    \n",
    "    -full_df=True if you want train and test as full dataframe (including the target)\n",
    "    \n",
    "Output :\n",
    "  \n",
    "    Return the train and test set where static is merge with the dynamic data where we get keept the mean , standard deviation , min and max of the time series.\n",
    "    If full_df=True, the output return 2 dataframe\n",
    "    If full_df=False , return 5 numpy array ( X_train, X_test, y_train, y_test and X_col (the name of the features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transplant.data.learningset import Learningset\n",
    "learningset = Learningset()\n",
    "\n",
    "train, test = learningset.get_data_merged_dynamic_flatten_full(full_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_donor</th>\n",
       "      <th>Aspirations_donor</th>\n",
       "      <th>BMI_donor</th>\n",
       "      <th>Donneur_CPT</th>\n",
       "      <th>Insuffisance_renale</th>\n",
       "      <th>LAS</th>\n",
       "      <th>PAPS</th>\n",
       "      <th>PFO</th>\n",
       "      <th>PF_donor</th>\n",
       "      <th>Poids</th>\n",
       "      <th>...</th>\n",
       "      <th>PNIm_min</th>\n",
       "      <th>PNIs_min</th>\n",
       "      <th>Pmax_min</th>\n",
       "      <th>Pmean_min</th>\n",
       "      <th>SpO2_min</th>\n",
       "      <th>SvO2 (m)_min</th>\n",
       "      <th>Temp_min</th>\n",
       "      <th>VT_min</th>\n",
       "      <th>declampage_cote1_done_min</th>\n",
       "      <th>declampage_cote2_done_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>25.502925</td>\n",
       "      <td>6750.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>25.502925</td>\n",
       "      <td>6151.95122</td>\n",
       "      <td>0</td>\n",
       "      <td>39.757613</td>\n",
       "      <td>94.677165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>22.481329</td>\n",
       "      <td>4950.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age_donor  Aspirations_donor  BMI_donor  Donneur_CPT  Insuffisance_renale  \\\n",
       "0         22                  3  25.502925   6750.00000                    0   \n",
       "1         56                  1  25.502925   6151.95122                    0   \n",
       "2         44                  1  22.481329   4950.00000                    0   \n",
       "\n",
       "         LAS       PAPS  PFO  PF_donor  Poids  ...  PNIm_min  PNIs_min  \\\n",
       "0  33.200000  32.000000  0.0     301.0   70.0  ...       0.0       0.0   \n",
       "1  39.757613  94.677165  0.0     388.0   52.0  ...       0.0       0.0   \n",
       "2  46.100000  60.000000  0.0     486.0   43.0  ...       0.0       0.0   \n",
       "\n",
       "   Pmax_min  Pmean_min  SpO2_min  SvO2 (m)_min  Temp_min  VT_min  \\\n",
       "0       0.0        0.0       0.0           0.0       0.0     0.0   \n",
       "1       0.0        0.0       0.0           0.0       0.0     0.0   \n",
       "2       0.0        0.0       0.0           0.0       0.0     0.0   \n",
       "\n",
       "   declampage_cote1_done_min  declampage_cote2_done_min  \n",
       "0                        0.0                        0.0  \n",
       "1                        0.0                        0.0  \n",
       "2                        0.0                        0.0  \n",
       "\n",
       "[3 rows x 143 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transplant.data.learningset import Learningset\n",
    "learningset = Learningset()\n",
    "\n",
    "X_train, X_test, y_train , y_test, X_col = learningset.get_data_merged_dynamic_flatten_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((228, 142), (102, 142), (228,), (102,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_data_merged_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_merged_dynamic(target_format=\"cls\", full_df=False):\n",
    "        from transplant.data.learningset import Learningset\n",
    "        learningset = Learningset()\n",
    "        \n",
    "        train_static_0, test_static_0 = learningset.get_static_filled()\n",
    "        train_dynamic_0, test_dynamic_0 = dataset.get_dynamic()\n",
    "\n",
    "        mean_dynamic_train = train_dynamic_0.groupby(['id_patient']).mean().mean() # Fill Nan with mean   \n",
    "        train_dynamic_0 = train_dynamic_0.fillna(mean_dynamic_train)\n",
    "        test_dynamic_0 = test_dynamic_0.fillna(mean_dynamic_train)\n",
    "\n",
    "        train_static_1 = add_start_end_length_op_to_static(train_static_0, train_dynamic_0) #Obtain length operation \n",
    "        test_static_1 = add_start_end_length_op_to_static(test_static_0, test_dynamic_0)\n",
    "            \n",
    "            \n",
    "        \n",
    "        train_glob = get_timeseries_in_array(train_static_1, train_dynamic_0) #Merge static and dynamic with full time series\n",
    "        test_glob = get_timeseries_in_array(test_static_1, test_dynamic_0) \n",
    "        \n",
    "        if full_df :\n",
    "            return  train_glob , test_glob\n",
    "\n",
    "        dic_to_One_Hot = {0: [1, 0], 1: [0, 1]}\n",
    "\n",
    "        y_train_cls = np.array(train_glob['target'])\n",
    "        y_train_hot = np.array(list(train_glob['target'].map(dic_to_One_Hot)))\n",
    "\n",
    "        y_test_cls = np.array(test_glob['target'])\n",
    "        y_test_hot = np.array(list(test_glob['target'].map(dic_to_One_Hot)))\n",
    "\n",
    "\n",
    "        X_train = np.array(train_glob.drop(['target'], axis=1))\n",
    "        X_test = np.array(test_glob.drop(['target'], axis=1))\n",
    "\n",
    "        # Return\n",
    "        if target_format == \"cls\":\n",
    "            return X_train, X_test, y_train_cls, y_test_cls, train_glob.drop(['target'], axis=1).columns\n",
    "\n",
    "        if target_format == \"One_Hot\":\n",
    "            return X_train, X_test, y_train_hot, y_test_hot, train_glob.drop(['target'], axis=1).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What it does :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input : \n",
    "\n",
    "    -target_format=\"cls\" if you want the target as 0 or 1 , \"One_Hot\" if you want the target to be [1,0] or [0,1]\n",
    "    \n",
    "    -full_df=True if you want train and test as full dataframe (including the target)\n",
    "    \n",
    "Output :\n",
    "  \n",
    "    Return the train and test set where static is merge with the dynamic data (full time series)\n",
    "    \n",
    "    If full_df=True, the output return 2 dataframe\n",
    "    If full_df=False , return 5 numpy array ( X_train, X_test, y_train, y_test and X_col (the name of the features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transplant.data.learningset import Learningset\n",
    "learningset = Learningset()\n",
    "\n",
    "train, test = get_data_merged_dynamic(full_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_donor</th>\n",
       "      <th>Aspirations_donor</th>\n",
       "      <th>BMI_donor</th>\n",
       "      <th>Donneur_CPT</th>\n",
       "      <th>Insuffisance_renale</th>\n",
       "      <th>LAS</th>\n",
       "      <th>PAPS</th>\n",
       "      <th>PFO</th>\n",
       "      <th>PF_donor</th>\n",
       "      <th>Poids</th>\n",
       "      <th>...</th>\n",
       "      <th>PNIm</th>\n",
       "      <th>PNIs</th>\n",
       "      <th>Pmax</th>\n",
       "      <th>Pmean</th>\n",
       "      <th>SpO2</th>\n",
       "      <th>SvO2 (m)</th>\n",
       "      <th>Temp</th>\n",
       "      <th>VT</th>\n",
       "      <th>declampage_cote1_done</th>\n",
       "      <th>declampage_cote2_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>25.502925</td>\n",
       "      <td>6750.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 108.0, 0.0, 0.0, 0.0, 102...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 142.0, 0.0, 0.0, 0.0, 130...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 0, ...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>[99, 99, 97, 97, 97, 97, 97, 97, 96, 96, 97, 9...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>25.502925</td>\n",
       "      <td>6151.95122</td>\n",
       "      <td>0</td>\n",
       "      <td>39.757613</td>\n",
       "      <td>94.677165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 2, 1, 4, 3, 2, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, ...</td>\n",
       "      <td>[99, 100, 100, 99, 99, 71, 100, 100, 100, 100,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>22.481329</td>\n",
       "      <td>4950.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[4.7212439550048755, 4.7212439550048755, 4.721...</td>\n",
       "      <td>[6.3442819371062615, 6.3442819371062615, 6.344...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[89, 90, 88, 91, 93, 94, 94, 95, 94, 94, 93, 9...</td>\n",
       "      <td>[46.77534140375992, 46.77534140375992, 46.7753...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age_donor  Aspirations_donor  BMI_donor  Donneur_CPT  Insuffisance_renale  \\\n",
       "0         22                  3  25.502925   6750.00000                    0   \n",
       "1         56                  1  25.502925   6151.95122                    0   \n",
       "2         44                  1  22.481329   4950.00000                    0   \n",
       "\n",
       "         LAS       PAPS  PFO  PF_donor  Poids  ...  \\\n",
       "0  33.200000  32.000000  0.0     301.0   70.0  ...   \n",
       "1  39.757613  94.677165  0.0     388.0   52.0  ...   \n",
       "2  46.100000  60.000000  0.0     486.0   43.0  ...   \n",
       "\n",
       "                                                PNIm  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 108.0, 0.0, 0.0, 0.0, 102...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [4.7212439550048755, 4.7212439550048755, 4.721...   \n",
       "\n",
       "                                                PNIs  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 142.0, 0.0, 0.0, 0.0, 130...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [6.3442819371062615, 6.3442819371062615, 6.344...   \n",
       "\n",
       "                                                Pmax  \\\n",
       "0  [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 0, ...   \n",
       "1  [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 2, 1, 4, 3, 2, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, ...   \n",
       "\n",
       "                                               Pmean  \\\n",
       "0  [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                                SpO2  \\\n",
       "0  [99, 99, 97, 97, 97, 97, 97, 97, 96, 96, 97, 9...   \n",
       "1  [99, 100, 100, 99, 99, 71, 100, 100, 100, 100,...   \n",
       "2  [89, 90, 88, 91, 93, 94, 94, 95, 94, 94, 93, 9...   \n",
       "\n",
       "                                            SvO2 (m)  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [46.77534140375992, 46.77534140375992, 46.7753...   \n",
       "\n",
       "                                                Temp  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                  VT  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                               declampage_cote1_done  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                               declampage_cote2_done  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[3 rows x 68 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
