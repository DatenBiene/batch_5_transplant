{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation , Once and for all !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize the data preparation we are performing for the different models we are building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea : \n",
    "    Could be good to update our classe to use this without having to copy and paste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transplant.tools.dataset import Dataset \n",
    "\n",
    "dataset = Dataset()\n",
    "\n",
    "train_static_0, test_static_0 = dataset.get_static()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_str_to_num=train_static_0.apply(pd.to_numeric,errors='coerce').dropna(1, how=\"all\")\n",
    "\n",
    "mean_train_static = train_static_str_to_num.mean()\n",
    "\n",
    "train_static_filled=train_static_str_to_num.fillna(mean_train_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_static_filled=test_static_0.apply(pd.to_numeric,errors='coerce').dropna(1, how=\"all\").fillna(mean_train_static)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make sure we got the same columns in train and test (static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_test=[]\n",
    "drop_train=[]\n",
    "train_static_columns=train_static_filled.columns\n",
    "test_static_columns=test_static_filled.columns\n",
    "\n",
    "for i in train_static_filled.columns :\n",
    "    if not(i in test_static_columns) :\n",
    "        drop_train+=[i]\n",
    "        \n",
    "for i in test_static_columns :\n",
    "    if not(i in train_static_filled.columns) :\n",
    "        drop_test+=[i]\n",
    "drop_test , drop_train\n",
    "\n",
    "train_static_filled=train_static_filled.drop(drop_train, axis=1)\n",
    "test_static_filled=test_static_filled.drop(drop_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_filled.shape, test_static_filled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to rescale our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def center_reduce_data(X_train,X_test):\n",
    "    mean_train=X_train.mean()\n",
    "    std_train=X_test.std()\n",
    "\n",
    "    return (X_train-mean_train)/std_train, (X_test-mean_train)/std_train\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train static we use for the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_static=train_static_filled\n",
    "test_static=test_static_filled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dynamic_0, test_dynamic_0 = dataset.get_dynamic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dynamic_0.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATTENTION ! HERE 30 patients missing in dynamic ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_id=train_static['id_patient'].sort_values().unique()\n",
    "dynamic_id=train_dynamic_0['id_patient'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_id.shape , dynamic_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_static_not_in_dynamic=[]\n",
    "in_dynamic_not_in_static=[]\n",
    "for i in static_id :\n",
    "    if not(i in dynamic_id):\n",
    "        in_static_not_in_dynamic+=[i]\n",
    "for i in dynamic_id:\n",
    "    if not(i in static_id):\n",
    "        in_dynamic_not_in_static+=[i]\n",
    "in_static_not_in_dynamic, in_dynamic_not_in_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_serie_patient(X,patient_id,variable) :\n",
    "    # On choisit la variable à observer dans table_col au dessus \n",
    "    df=X[X['id_patient']==patient_id].sort_values('time') ;\n",
    "    df['time']-=df['time'].iloc[0] ; # Ici j'initialise le temps à 0. Càd le début est à 0.\n",
    "    df=df.set_index('time') ;\n",
    "    plt.title('Evolution de la variable \"'+variable+'\" du patient '+str(patient_id)+\"| Durée de l'opération : \"+str(df.index[-1]), y=1.05, size=25)\n",
    "    plt.plot(df[variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,16))\n",
    "plot_serie_patient(train_dynamic_0,1,'BIS SR')\n",
    "plot_serie_patient(train_dynamic_0,2,'BIS SR')\n",
    "plot_serie_patient(train_dynamic_0,3,'BIS SR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace NaN dynamic with mean train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dynamic_train=train_dynamic_0.groupby(['id_patient']).mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dynamic=train_dynamic_0.fillna(mean_dynamic_train)\n",
    "test_dynamic=test_dynamic_0.fillna(mean_dynamic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dynamic_flat=train_dynamic.groupby(['id_patient'], as_index=False).mean()\n",
    "test_dynamic_flat=test_dynamic.groupby(['id_patient'],as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dynamic_flat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum up before merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge dynamic and static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_dyn_sta(X_train_static,X_train_dynamic,X_test_static,X_test_dynamic):\n",
    "    return pd.merge(X_train_static, X_train_dynamic, on='id_patient') , pd.merge(X_test_static, X_test_dynamic, on='id_patient') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_glob, test_glob = merge_dyn_sta(train_static,train_dynamic_flat,test_static,test_dynamic_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_glob.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic_to_One_Hot = {0 : [1,0], 1 : [0,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(train_glob.drop(['target'], axis=1))\n",
    "X_test=np.array(test_glob.drop(['target'], axis=1))\n",
    "\n",
    "y_train_cls=np.array(train_glob['target'])\n",
    "y_train_hot=np.array(list(train_glob['target'].map(dic_to_One_Hot)))\n",
    "\n",
    "y_test_cls=np.array(test_glob['target'])\n",
    "y_test_hot=np.array(list(test_glob['target'].map(dic_to_One_Hot)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All this for that !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Delanoue\\Documents\\GitHubRepo\\batch_5_transplant\\transplant\\tools\\dataset.py:134: FutureWarning: 'id_patient' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  mean_dynamic_train=train_dynamic_0.groupby(['id_patient']).mean().mean()\n",
      "C:\\Users\\Delanoue\\Documents\\GitHubRepo\\batch_5_transplant\\transplant\\tools\\dataset.py:139: FutureWarning: 'id_patient' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  train_dynamic_flat=train_dynamic.groupby(['id_patient'], as_index=False).mean()\n",
      "C:\\Users\\Delanoue\\Documents\\GitHubRepo\\batch_5_transplant\\transplant\\tools\\dataset.py:140: FutureWarning: 'id_patient' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  test_dynamic_flat=test_dynamic.groupby(['id_patient'],as_index=False).mean()\n"
     ]
    }
   ],
   "source": [
    "from transplant.tools.dataset import Dataset \n",
    "\n",
    "dataset = Dataset()\n",
    "\n",
    "X_train, X_test , y_train, y_test = dataset.get_data_pierre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
